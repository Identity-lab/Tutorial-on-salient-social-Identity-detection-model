{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the python implementation of the paper \"Predicting a Salient Social Identity from Linguistic Style\"\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial is aimed at readers who have a basic familiarity with Python; if you have not previously used Python, we recommend that you start by taking the course \"Introduction to Data Science in Python\" from coursera (https://www.coursera.org/learn/python-data-analysis). \n",
    "\n",
    "Please see the original paper for the detailed description of the procedure. (Lines starting with \"#\" are comments and will not be executed by Python.)\n",
    "\n",
    "In order to run the code, first you need to\n",
    "\n",
    "- download the dataset\n",
    "- copy the dataset in a folder named data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying some parameters\n",
    "\n",
    "We first need to specify some parameters: \n",
    "\n",
    "1) Size of the training dataset. Here we chose 50000 posts from each forum of parent and femnist (by specifying batch_size = 50000). \n",
    "\n",
    "2) As posts are randomly selected for both training and test, we run our analysis for multiple times, which can be specified by Max_Iter parameter. \n",
    "\n",
    "3) If you want to include only posts which are longer than a specified threshold, you can set WORD_LIMIT = true, and choose the minimum word count by setting MIN_WC parameter. \n",
    "\n",
    "4) DBDIR is pointing to directory that contains dataset, and SAVEDIR is destination for saving the trained model. \n",
    "\n",
    "5) Here we considered all the stylistic features for training our identity detection model, however, any subset of these features can be considered. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 50000\n",
    "MAX_Iter = 20\n",
    "WORD_LIMIT = False\n",
    "MIN_WC = 25\n",
    "\n",
    "DBDIR = './data/Mumsnet_parent_feminist.csv'\n",
    "SAVEDIR = './save_dir/logr.sav'\n",
    "\n",
    "# all LIWC stylistic features\n",
    "ALL_STYLISTIC_FEATURES = ['WPS', 'i', 'we', 'you', 'shehe', 'they', 'ipron','article', 'auxverb', 'past',\n",
    "                    'present', 'future', 'adverb', 'preps','conj', 'quant', 'number', 'time', 'Sixltr',\n",
    "                    'Period', 'Colon', 'SemiC', 'QMark', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP',\n",
    "                    'negate', 'swear', 'posemo','negemo', 'assent', 'nonfl', 'filler', 'Exclam', 'insight',\n",
    "                    'cause', 'discrep', 'tentat', 'certain', 'inhib', 'incl', 'excl']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utility functions\n",
    "\n",
    "This section contains functions which prepare data for training and testing.\n",
    "\n",
    "\n",
    "### Reading input files \n",
    "We first read csv files, and preprocess them by removing rows which contain Nan value and dropping short posts if it is specified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def read_csv(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except:\n",
    "        print('error in reading file')\n",
    "        raise\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocessing(df, word_limit=False, min_WC=25):\n",
    "    df = df.dropna()\n",
    "    if word_limit:\n",
    "        df = df.loc[df['WC'] >= min_WC]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buiding train and test sets\n",
    "\n",
    "In order to build train and test set, we first need to separate users into between and within participants. \n",
    "\n",
    "Within pariticipants are users who are participating in both forums by posting at least once in each forums. Between participants are those who have posted only in one forum (feminist or parent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separating_users(df):\n",
    "    fem_df = df.loc[df.forum_id == 1]\n",
    "    par_df = df.loc[df.forum_id == 0]\n",
    "    \n",
    "    # participants who are posting in both forums\n",
    "    within_p = set(fem_df.user_id.unique()).intersection(par_df.user_id.unique())\n",
    "    # participants who are posting only in one forum, parent or feminist\n",
    "    between_p = df[~df.user_id.isin(within_p)].user_id.unique()\n",
    "\n",
    "    return between_p, within_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the test set by randomly choosing one post per forum for each within participant, if there is no limit on size of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_testcases(posts_within, within_participants, no=None):\n",
    "    # randomly selecting one post per forum for each within participant\n",
    "    testDB = posts_within.sample(frac=1)\n",
    "    testDB = testDB.drop_duplicates(subset=['user_id', 'forum_id'])\n",
    "\n",
    "    # if there is no limit on the number of test cases, choose one post per forum\n",
    "    # for each within participant, otherwise, randomly choose no number users from\n",
    "    # within participants\n",
    "    if no is not None:\n",
    "        testUsers = np.random.choice(within_participants, no, replace=False)\n",
    "        testDB = testDB.loc[testDB['user_id'].isin(testUsers)]\n",
    "\n",
    "    return testDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set is build by randomly choosing posts from between participants, and test set is build by randomly choosing two posts from each within participant per forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, batch, word_limit, min_WC, features, standardize=False, verbose=True):\n",
    "    df = preprocessing(df, word_limit, min_WC)\n",
    "\n",
    "    # separating users into between and withing participants\n",
    "    between_participants, within_participants = separating_users(df.copy())\n",
    "    \n",
    "    if verbose:\n",
    "        print('number of within participants are:{}'.format(len(within_participants)))\n",
    "        print('number of between participants are:{}'.format(len(between_participants)))\n",
    "\n",
    "\n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    # buiding train set by randomly selecting posts from between participants\n",
    "    fem_posts_between = df[(df['user_id'].isin(between_participants)) & (df['forum_id'] == 1)][:batch]\n",
    "    par_posts_between = df[(df['user_id'].isin(between_participants)) & (df['forum_id'] == 0)][:batch]\n",
    "    trainDB = pd.concat([fem_posts_between, par_posts_between])\n",
    "\n",
    "    # buidling test set by randomly selecting one posts per from from each within participant\n",
    "    posts_within = df[df['user_id'].isin(within_participants)]\n",
    "    testDB = extract_testcases(posts_within, within_participants)\n",
    "\n",
    "    if standardize:\n",
    "        scaler = StandardScaler().fit(trainDB[features])\n",
    "        trainDB[params.features] = scaler.transform(trainDB[features])\n",
    "        testDB[params.features] = scaler.transform(testDB[features])\n",
    "\n",
    "    return trainDB, testDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "\n",
    "### Choosing a model for training\n",
    "\n",
    "Here we apply Logistic regression for training our model. If grid_search is true, best parameter would be chosen for the model, but it takes longer to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "def Logistic_Regression(grid_search=False):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter = 500)\n",
    "\n",
    "    if grid_search:\n",
    "        tuned_parameters = [{'C': [1e-3, 1e-2, 1e-1, 1]}]\n",
    "        clf = GridSearchCV(LogisticRegression(solver='lbfgs'), tuned_parameters, cv=10,\n",
    "                           scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train(X_train, y_train, save_dir, verbose=True, save_model=True):\n",
    "    model = Logistic_Regression()\n",
    "\n",
    "    # training accuracy and AUC\n",
    "    tr_auc = np.mean(cross_val_score(model, X_train, y_train, cv=10, scoring='roc_auc'))\n",
    "    tr_acc = np.mean(cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if save_model:\n",
    "        joblib.dump(model, save_dir)\n",
    "\n",
    "    if verbose:\n",
    "        print('model is trained')\n",
    "\n",
    "    return model, tr_auc, tr_acc\n",
    "\n",
    "\n",
    "def test(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    s = clf.decision_function(X_test)\n",
    "    auc = roc_auc_score(y_test, s)\n",
    "\n",
    "    return acc, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the identity detection model\n",
    "We then run training and testing for multiple times (here we set that as 20 iterations). In each iteration 100000 posts are randomly selected from the between participant users, which are equally coming from feminist and parent posts. Test set is also built by randomly selecting one post per each within participant from each forum. \n",
    "\n",
    "We report the AUC and accuracy of our identity detection model by averaging over the results from multiple iterations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run(df, batch_size, features, max_iter, word_limit, word_count, save_dir, verbose=True):\n",
    "\n",
    "    tr_results= []\n",
    "    tt_results = []\n",
    "    for T in range(max_iter):\n",
    "        print('round:{}'.format(T + 1))\n",
    "\n",
    "        trainingDB, testDB = split_train_test(df.copy(deep=True), batch_size, word_limit, word_count, features)\n",
    "        X_train, y_train = trainingDB[features], trainingDB['forum_id']\n",
    "        X_test, y_test = testDB[features], testDB['forum_id']\n",
    "\n",
    "        model, tr_auc, tr_acc = train(X_train, y_train, save_dir)\n",
    "        if verbose:\n",
    "            print('training accuracy:{}'.format(tr_acc), 'training AUC :{}'.format(tr_auc))\n",
    "\n",
    "        tt_acc, tt_auc = test(model, X_test, y_test)\n",
    "\n",
    "        if verbose:\n",
    "            print('test accuracy:{}'.format(tt_acc), 'test AUC :{}'.format(tt_auc))\n",
    "\n",
    "        tr_results.append({'acc': tr_acc, 'auc': tr_auc})\n",
    "        tt_results.append({'acc': tt_acc, 'auc': tt_auc})\n",
    "\n",
    "    return tr_results, tt_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = Batch_Size\n",
    "    max_iter = MAX_Iter\n",
    "    min_WC = MIN_WC\n",
    "    word_limit = WORD_LIMIT\n",
    "    features = ALL_STYLISTIC_FEATURES\n",
    "    dbdir = DBDIR\n",
    "    save_dir = SAVEDIR\n",
    "\n",
    "    df = read_csv(dbdir)\n",
    "\n",
    "    tr_results, tt_results= run(df.copy(deep=True), batch_size, features, max_iter, word_limit, min_WC, save_dir)\n",
    "\n",
    "    print('training_auc:', 'AUC_mean:{}'.format(np.mean([item['auc'] for item in tr_results])),\n",
    "          'AUC_std:{}'.format(np.std([item['auc'] for item in tr_results])))\n",
    "\n",
    "    print('training_acc:', 'acc_mean:{}'.format(np.mean([item['acc'] for item in tr_results])),\n",
    "          'acc_std:{}'.format(np.std([item['acc'] for item in tr_results])))\n",
    "\n",
    "    print('testing_auc:', 'AUC_mean', np.mean([item['auc'] for item in tt_results]), 'AUC_std',\n",
    "          np.std([item['auc'] for item in tt_results]))\n",
    "\n",
    "    print('testing_acc:', 'acc_mean:{}'.format(np.mean([item['acc'] for item in tt_results])),\n",
    "          'acc_std:{}'.format(np.std([item['acc'] for item in tt_results])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
