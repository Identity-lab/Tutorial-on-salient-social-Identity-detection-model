{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** If unfamiliar with Jupyter Notebooks, instructions for installing and running can be found here: http://jupyter.org/install. Before installing Jupyter Notebook, make sure that Python is installed (our code is with Python3) in your system. We recommend installing Python and Jupyter using the conda package manager.***\n",
    "\n",
    "\n",
    "\n",
    "This is the python implementation of the paper \"ASIA: Automated Social Identity Assessment Using Linguistic Style\"\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial is aimed at readers who have a basic familiarity with Python; if you have not previously used Python, we recommend that you start by taking the course \"Introduction to Data Science in Python\" from coursera (https://www.coursera.org/learn/python-data-analysis). \n",
    "\n",
    "Please see the original paper for the detailed description of the procedure. (Lines starting with \"#\" are comments and will not be executed by Python.)\n",
    "\n",
    "In order to run the code, first you need to\n",
    "\n",
    "- download the datasets (Mumsnet_feminist_parent.csv, Reddit_feminist_parent.csv, Experimental_data.csv)\n",
    "- copy the datasets in a folder named data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "DBDIR is pointing to directory that contains dataset (data folder), and SAVEDIR is destination for saving the trained model (if you want). \n",
    "\n",
    "Here we considered all the stylistic LIWC features for training our identity detection model, however, any subset of these features can be considered. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DBDIR = './data/'\n",
    "Mumsnet_DB = 'Mumsnet_feminist_parent.csv'\n",
    "Reddit_DB = 'Reddit_feminist_parent.csv'\n",
    "Experimental_DB = 'Experimental_data_within.csv' # or 'Experimental_data_between.csv'\n",
    "\n",
    "SAVEDIR = './save_dir/logr.sav'\n",
    "\n",
    "# all LIWC stylistic features\n",
    "ALL_STYLISTIC_FEATURES = ['WPS', 'i', 'we', 'you', 'shehe', 'they', 'ipron','article', 'auxverb', 'past',\n",
    "                    'present', 'future', 'adverb', 'preps','conj', 'quant', 'number', 'time', 'Sixltr',\n",
    "                    'Period', 'Colon', 'SemiC', 'QMark', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP',\n",
    "                    'negate', 'swear', 'posemo','negemo', 'assent', 'nonfl', 'filler', 'Exclam', 'insight',\n",
    "                    'cause', 'discrep', 'tentat', 'certain', 'inhib', 'incl', 'excl']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utility functions\n",
    "\n",
    "This section contains functions which prepare data for training and testing.\n",
    "\n",
    "\n",
    "### Reading input files \n",
    "We first read csv files, and preprocess them by removing rows which contain Nan value and dropping short posts if it is specified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def preprocessing(df, word_limit, min_WC):\n",
    "    df = df.dropna()\n",
    "    if word_limit:\n",
    "        df = df.loc[df['WC'] >= min_WC]\n",
    "    return df\n",
    "\n",
    "def read_csv(path, word_limit, min_WC):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except:\n",
    "        print('error in reading file')\n",
    "        raise\n",
    "    df = preprocessing(df, word_limit, min_WC)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buiding train and test sets\n",
    "\n",
    "In order to build train and test set, we first need to separate users into between and within participants. \n",
    "\n",
    "Within pariticipants are users who are participating in both forums by posting at least once in each forums. Between participants are those who have posted only in one forum (feminist or parent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separating_users(df):\n",
    "    fem_df = df.loc[df.forum_id == 1]\n",
    "    par_df = df.loc[df.forum_id == 0]\n",
    "    \n",
    "    # participants who are posting in both forums\n",
    "    within_p = set(fem_df.user_id.unique()).intersection(par_df.user_id.unique())\n",
    "    # participants who are posting only in one forum, parent or feminist\n",
    "    between_p = df[~df.user_id.isin(within_p)].user_id.unique()\n",
    "\n",
    "    return between_p, within_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the test set by randomly choosing one post per forum for each within participant, if there is no limit on size of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_testcases(posts_within, no=None):\n",
    "    # randomly selecting one post per forum for each within participant\n",
    "    testDB = posts_within.sample(frac=1)\n",
    "    testDB = testDB.drop_duplicates(subset=['user_id', 'forum_id'])\n",
    "\n",
    "    # if there is no limit on the number of test cases, choose one post per forum\n",
    "    # for each within participant, otherwise, randomly choose no number users from\n",
    "    # within participants\n",
    "    if no is not None:\n",
    "        within_participants = posts_within.user_id.unique()\n",
    "        testUsers = np.random.choice(within_participants, no, replace=False)\n",
    "        testDB = testDB.loc[testDB['user_id'].isin(testUsers)]\n",
    "\n",
    "    return testDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set is build by randomly choosing posts from between participants, and test set is build by randomly choosing two posts from each within participant one per forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_between_within_sets(df):\n",
    "    # separating users into between and withing participants\n",
    "    between_participants, within_participants = separating_users(df.copy())\n",
    "\n",
    "    within_set = df.loc[df.user_id.isin(within_participants)]\n",
    "    between_set = df.loc[df.user_id.isin(between_participants)]\n",
    "    \n",
    "    return between_set, within_set\n",
    "\n",
    "\n",
    "def get_train_set(sub_df, batch, verbose=True):\n",
    "    sub_df = sub_df.sample(frac=1)\n",
    "\n",
    "    # buiding train set by randomly selecting posts\n",
    "    posts_forum1 = sub_df[sub_df['forum_id'] == 1][:batch]\n",
    "    posts_forum0 = sub_df[sub_df['forum_id'] == 0][:batch]\n",
    "    trainDB = pd.concat([posts_forum1, posts_forum0])\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\ntrain set size:{}'.format(trainDB.shape[0]))\n",
    "    \n",
    "    return trainDB\n",
    "    \n",
    "\n",
    "def get_test_set(sub_df, batch, verbose=True):\n",
    "    sub_df = sub_df.sample(frac=1)\n",
    "    \n",
    "\n",
    "    # buidling test set by randomly selecting one posts per from from each within participant\n",
    "    testDB = extract_testcases(sub_df)\n",
    "    \n",
    "    if verbose:\n",
    "        print('test set size:{}\\n'.format(testDB.shape[0]))\n",
    "        \n",
    "        \n",
    "    return testDB\n",
    "\n",
    "\n",
    "def train_test_prepration(trainDB, testDB, features, standardize=False):\n",
    "    if standardize:\n",
    "        scaler = StandardScaler().fit(trainDB[features])\n",
    "        trainDB[params.features] = scaler.transform(trainDB[features])\n",
    "        testDB[params.features] = scaler.transform(testDB[features])\n",
    "\n",
    "    return trainDB, testDB\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "\n",
    "### Choosing a model for training\n",
    "\n",
    "Here we apply Logistic regression for training our model. If grid_search is true, best parameter would be chosen for the model, but it takes longer to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "def Logistic_Regression(penalty, grid_search=False):\n",
    "    clf = LogisticRegression(solver='lbfgs', penalty=penalty, max_iter = 2000)\n",
    "\n",
    "    if grid_search:\n",
    "        tuned_parameters = [{'C': [1e-3, 1e-2, 1e-1, 1]}]\n",
    "        clf = GridSearchCV(LogisticRegression(solver='lbfgs', penalty=penalty), tuned_parameters, cv=10,\n",
    "                           scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    return clf\n",
    "\n",
    "\n",
    "def train(X_train, y_train, cross_val=True, save_dir=SAVEDIR, verbose=True, save_model=True):\n",
    "    \n",
    "    # to add the regularization, you can set penalty=‘l1’ or penalty=‘l2’ (depending on the solver).\n",
    "    model = Logistic_Regression(penalty='none')\n",
    "\n",
    "    # training accuracy and AUC\n",
    "    tr_auc, tr_acc = None, None\n",
    "    if cross_val:\n",
    "        tr_auc = np.mean(cross_val_score(model, X_train, y_train, cv=10, scoring='roc_auc'))\n",
    "        tr_acc = np.mean(cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if save_model:\n",
    "        joblib.dump(model, save_dir)\n",
    "\n",
    "    if verbose:\n",
    "        print('model is trained')\n",
    "\n",
    "    return model, tr_auc, tr_acc\n",
    "\n",
    "\n",
    "def test(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    s = clf.decision_function(X_test)\n",
    "    auc = roc_auc_score(y_test, s)\n",
    "\n",
    "    return acc, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the identity detection model\n",
    "We then run training and testing for multiple times. In each iteration specified number of posts are randomly selected from the between participant users, which are equally coming from both forums (feminist and parent). Test set is also built by randomly selecting one post per each within participant from each forum. \n",
    "\n",
    "We first need to specify some parameters: \n",
    "\n",
    "1) Size of the training dataset. Here we chose 50000 posts from each forum of parent and femnist (by specifying batch_size = 50000). \n",
    "\n",
    "2) As posts are randomly selected for both training and test, we run our analysis for multiple times, which can be specified by Max_Iter parameter. \n",
    "\n",
    "3) If you want to include only posts which are longer than a specified threshold, you have to set word_limit=true, and choose the minimum word count by setting min_WC parameter. \n",
    "\n",
    "We report the AUC and accuracy of our identity detection model by averaging over the results from multiple iterations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run(trainingDB, testDB, features, max_iter, save_dir, verbose=True):\n",
    "\n",
    "    tr_results= []\n",
    "    tt_results = []\n",
    "    for T in range(max_iter):\n",
    "        print('\\nround:{}'.format(T + 1))\n",
    "\n",
    "        X_train, y_train = trainingDB[features], trainingDB['forum_id']\n",
    "        X_test, y_test = testDB[features], testDB['forum_id']\n",
    "\n",
    "        model, tr_auc, tr_acc = train(X_train, y_train, save_dir)\n",
    "        if verbose:\n",
    "            print('training accuracy:{}'.format(tr_acc), 'training AUC :{}'.format(tr_auc))\n",
    "\n",
    "        tt_acc, tt_auc = test(model, X_test, y_test)\n",
    "\n",
    "        if verbose:\n",
    "            print('test accuracy:{}'.format(tt_acc), 'test AUC :{}'.format(tt_auc))\n",
    "\n",
    "        tr_results.append({'acc': tr_acc, 'auc': tr_auc})\n",
    "        tt_results.append({'acc': tt_acc, 'auc': tt_auc})\n",
    "\n",
    "    return tr_results, tt_results\n",
    "\n",
    "\n",
    "def main(verbose=True):\n",
    "    batch_size = 50000\n",
    "    max_iter = 1\n",
    "    word_limit = True\n",
    "    min_WC = 25\n",
    "    features = ALL_STYLISTIC_FEATURES\n",
    "    standardize = False\n",
    "    \n",
    "    dbdir = DBDIR\n",
    "    save_dir = SAVEDIR\n",
    "    \n",
    "    \n",
    "    # choose the dataset you want to test the trained model on\n",
    "    testing_on = 'mumsnet'\n",
    "    \n",
    "\n",
    "    # reading datasets from CSV files\n",
    "    mumsnet_df = read_csv(dbdir + Mumsnet_DB, word_limit, min_WC)\n",
    "    reddit_df = read_csv(dbdir + Reddit_DB, word_limit, min_WC)\n",
    "    experimental_df = read_csv(dbdir + Experimental_DB, word_limit=False, min_WC=min_WC)\n",
    "    \n",
    "    if verbose:\n",
    "        print('size of mumsnet dataset:{}'.format(mumsnet_df.shape[0]))\n",
    "        print('size of reddit dataset:{}'.format(reddit_df.shape[0]))\n",
    "        print('size of experimental dataset:{}'.format(experimental_df.shape[0]))\n",
    "        \n",
    "        \n",
    "    trainDB = get_train_set(mumsnet_df.copy(deep=True), batch_size)\n",
    "    \n",
    "    \n",
    "    if testing_on == 'mumsnet':\n",
    "        between_set, within_set = split_between_within_sets(\n",
    "            mumsnet_df.loc[~mumsnet_df.msg_id.isin(trainDB.msg_id)].copy(deep=True))\n",
    "        testDB = get_test_set(within_set, batch_size)\n",
    "    elif testing_on == 'reddit':\n",
    "        reddit_between_set, reddit_within_set = split_between_within_sets(reddit_df)\n",
    "        testDB = get_test_set(reddit_within_set, batch_size)\n",
    "    elif testing_on == 'experimental':\n",
    "        # choose the topic you want to test on\n",
    "        # there are three topics: healthy mealtimes ('hm'), \n",
    "        # objectification of women ('ow')\n",
    "        # and climate change ('cc')\n",
    "        topic = 'ow'\n",
    "        testDB = experimental_df.loc[experimental_df['topic'] == topic]\n",
    "        testDB = testDB.rename(columns = {'condition' : 'forum_id'})\n",
    "        \n",
    "        \n",
    "    trainDB, testDB = train_test_prepration(trainDB, testDB, features, standardize)\n",
    "    \n",
    "\n",
    "\n",
    "    tr_results, tt_results = run(trainDB, testDB, features, max_iter, save_dir)\n",
    "\n",
    "    if max_iter > 1:\n",
    "        print('\\n Accuracy and AUC after {} iteration(s):'.format(max_iter))\n",
    "        print('training_auc:', 'AUC_mean:{}'.format(np.mean([item['auc'] for item in tr_results])),\n",
    "              'AUC_std:{}'.format(np.std([item['auc'] for item in tr_results])))\n",
    "\n",
    "        print('training_acc:', 'acc_mean:{}'.format(np.mean([item['acc'] for item in tr_results])),\n",
    "              'acc_std:{}'.format(np.std([item['acc'] for item in tr_results])))\n",
    "\n",
    "        print('testing_auc:', 'AUC_mean', np.mean([item['auc'] for item in tt_results]), 'AUC_std',\n",
    "              np.std([item['auc'] for item in tt_results]))\n",
    "\n",
    "        print('testing_acc:', 'acc_mean:{}'.format(np.mean([item['acc'] for item in tt_results])),\n",
    "              'acc_std:{}'.format(np.std([item['acc'] for item in tt_results])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of mumsnet dataset:461371\n",
      "size of reddit dataset:388096\n",
      "size of experimental dataset:128\n",
      "\n",
      "train set size:100000\n",
      "test set size:3954\n",
      "\n",
      "\n",
      "round:1\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
